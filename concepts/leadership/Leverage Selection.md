# Leverage Selection

The most valuable skill isn't solving problems — it's recognizing which level of the system to intervene at.

---

## The Systems Thinking Gradient

Higher-level interventions have more leverage:

```
Actions → Behaviors → Structures → Mental Models
              ↑ Increasing Leverage ↑
```

Fixing an action is easy but temporary. Changing a mental model is hard but permanent.

---

## The Pattern Across Domains

| Domain | Low Leverage | High Leverage |
|--------|--------------|---------------|
| Leadership | Fix the bug (event) | Change the process (structure) |
| Design | Clean the code | Improve the architecture |
| Decisions | Solve the problem | Reframe the problem ([[TOSCA]]) |
| AI Dev | Use AI faster | Change what you're building |
| Philosophy | Work harder | Work on the right thing ([[Ikigai]]) |

---

## The Synthesis

**Where you apply effort matters more than how much effort you apply.**

This is the meta-skill: recognizing that most problems can be addressed at multiple levels, and choosing the level with the highest leverage.

The trap is that low-leverage interventions *feel* productive:
- Fixing bugs feels like progress
- Working harder feels virtuous
- Solving problems feels valuable

But these are often symptoms. The high-leverage move is asking: *why does this problem keep recurring?*

---

## The Iceberg Model

From [[Systems Thinking]]:

```
        Events          ← What happened? (reactive)
       Patterns         ← What trends? (anticipate)
      Structures        ← What causes patterns? (design)
    Mental Models       ← What beliefs drive structures? (transform)
```

Each level down has more leverage — and requires more courage to address.

---

## Application

When facing a problem:

1. **Ask "why" repeatedly** — Move down the iceberg
2. **Resist the urge to fix the event** — It will recur
3. **Look for patterns** — Where have you seen this before?
4. **Identify the structure** — What system produces this pattern?
5. **Question the mental model** — What belief makes this structure seem sensible?

The highest-leverage intervention is often the most uncomfortable one.

---

## Related Concepts

- [[Systems Thinking]] — The iceberg model and leverage points
- [[TOSCA]] — Problem-reframing as high-leverage intervention
- [[Ikigai]] — Working on the right thing > working hard
- [[The Great Inversion]] — Clarity (what to build) > execution (building it)
- [[Agents vs Long Context]] — Agents operate at action level; long context at structure/model level

## Connection to Other Syntheses

This is one of three related frameworks about **resource allocation under uncertainty**:

| Synthesis | Allocates... | Based on... |
|-----------|--------------|-------------|
| [[Reversibility-Calibrated Action]] | Speed | Cost of mistakes |
| **Leverage Selection** | Effort | Impact level |
| [[Signal in the Scar]] | Visibility | Value of learning |

Leverage Selection sits at the top of this hierarchy — it's the meta-question of *where* to intervene, while the other two address *how fast* and *how visibly*.

**The unified stance:** Act quickly on reversible things, intervene at high leverage points, and make your learning visible.

---

## See Also

- [[_MOCs/Leadership & Teams]] — Back to the MOC
- [[Scarcity to Abundance - A Unifying Lens]] — Another cross-domain synthesis
- [[SAGE Synthesis]] — The synthesis log

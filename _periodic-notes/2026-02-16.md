# 2026-02-16

← [[2026-02-15]] | [[2026-02-17]] →

---

## KB Maintenance

Restructured notes to move related links closer to the concepts they reference, rather than having disjointed lists at the bottom.

**Files updated:**

- [[Reversibility-Calibrated Action]] — Added "The Bike Principle" section explaining the connection to [[The Collapse of Roles and Time]] and [[Rules of Thumb]] in context
- [[Rules of Thumb]] — Wove reversibility links into "On Speed" section; transformed Related Concepts into "When Heuristics Fail" with explanatory context
- [[The Collapse of Roles and Time]] — Added Rules of Thumb quote to Bike Principle section; removed redundant list (Connection to Other Concepts section already had contextual links)
- [[Teach the Delta]] — Added [[The Collapse of Roles and Time]] to Connection section
- [[Context Distillation Loop - amnesia as a feature]] — Added missing connections (Teach the Delta, Leverage Selection, The 2026 Builder Operating System, Scarcity to Abundance) to Connection section

**Pattern established:** Links belong in contextual sections that explain *why* the connection matters. Keep only minimal "See Also" for MOC navigation.

---

## Meta

Created `.claude/CLAUDE.md` to document rules for AI agents working on this KB. Key principle: links close to definitions, not at the bottom.

---

## New Notes Added

### [[concepts/ai-development/Agentation - UI Element Annotation|Agentation (UI Element Annotation)]]
Visual feedback instrument for AI coding agents — click page elements, get CSS selectors for grep searches. Bridges "that button" (visual) to code references. A tool for High-Quality Intent Specification.

### [[concepts/ai-development/Scalable Multi-Agent Architecture|Scalable Multi-Agent Architecture]]
The "human team" fallacy: mimicking human collaboration fails at scale. Five rules from Cursor/Gastown: two tiers not teams, workers stay ignorant, no shared state, plan for endings (episodic operation), sophisticated orchestration + simple agents. Creates productive tension with [[Teams Of Agents - LLM Specialisation+Personas]] — different tools for different scales.

### [[concepts/ai-development/Law vs Physics in Agent Design|Law vs Physics in Agent Design]]
Fundamental distinction for reliable agentic systems. **Law** (prompts) = voluntary, degrades under context pressure. **Physics** (API/platform) = involuntary, cannot be bypassed. Design rule: for every Law, ask "What happens when the agent ignores this?" — if catastrophic, add Physics. Extracted from AMP multi-agent coordination planning doc.

### [[concepts/design-principles/Database Physics vs Policy|Database Physics vs Policy]]
Decision framework for **Columns vs JSONB** in schema design. Three litmus tests: (1) Foreign Key Test — references another table? Column. (2) Indexing/Poller Test — background job queries it? Column. (3) Write-Path Gatekeeper Test — checked on hot-path? Column. Copy-Down pattern (resolve settings at creation time) beats Runtime Lookup (join 3 tables every query). Same Law vs Physics philosophy at the infrastructure layer.

### [[concepts/design-principles/Physics Thinking|Physics Thinking]] ⭐ Synthesis
The umbrella meta-principle: at every layer of your system, distinguish what components *should* do (Law/Policy) from what they *can* do (Physics). Ensure catastrophic failures are prevented by Physics, not just discouraged by Law. Applies across agents, APIs, databases, UI, infrastructure. The goal isn't perfect compliance — it's **bounded failure**. Ties together Law vs Physics in Agent Design and Database Physics vs Policy.

---

## New Reference Notes

### [[reference/How to Document a Project|How to Document a Project]]
Practical how-to guide for developers setting up project documentation. Covers minimum viable docs (README, ADRs, runbook, API contracts), folder structure, keeping docs current, and making docs AI-agent friendly. Builds on [[Strategic vs Tactical Documentation]] as its conceptual foundation.

---

## Files Updated

- [[concepts/ai-development/Scalable Multi-Agent Architecture|Scalable Multi-Agent Architecture]] — Added Law vs Physics connection to existing patterns table
- [[concepts/ai-development/Agents vs Long Context|Agents vs Long Context]] — Added orchestration pattern section linking to Context Distillation Loop
- [[concepts/ai-development/Law vs Physics in Agent Design|Law vs Physics in Agent Design]] — Added Physics Thinking cross-reference
- [[concepts/design-principles/Database Physics vs Policy|Database Physics vs Policy]] — Added Physics Thinking cross-reference
- [[_MOCs/AI-Assisted Development]] — Added Agentation, Scalable Multi-Agent Architecture, Law vs Physics entries
- [[_MOCs/Design Principles]] — Added Taste in Software, Database Physics vs Policy, Physics Thinking entries
- [[concepts/design-principles/Physics Thinking|Physics Thinking]] — Added "When Law is Better Than Physics" section for balance
- [[SAGE Synthesis]] — Logged all new notes + Physics Thinking synthesis
